{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JCP Surrodash K-Fold Cross Validation Example Notebook\n",
    "The following two blocks are used for loading the correct files and dependencies from the Github repo to be able to run the ML modelling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALL NOTEBOOK SHOULD HAVE SOME VERSION OF THIS #####################################\n",
    "########################################################################################\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "currentdir = os.getcwd()\n",
    "# go to root directory. change the # of os.path.dirnames based on where currentdir is\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "# chek where I'm at. if I go too far up the tree, go back\n",
    "if 'Protein-Purification-Model-Public' not in parentdir: parentdir = currentdir\n",
    "if parentdir not in sys.path: sys.path.insert(0,parentdir)\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "# import py_files\n",
    "\n",
    "import utils\n",
    "import visualization.simple_data_vis as vis\n",
    "import surrogate_models.nn_defs as engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from just-private/data\n",
    "filename = 'mol_res_scan_results_7.csv'\n",
    "data = utils.load_data(parentdir, filename)\n",
    "\n",
    "# since currently data is just one big dataframe, select model inputs as X and purity, yield as Y\n",
    "x = [*data.columns[:2],*data.columns[4:]]\n",
    "y = data.columns[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we first clean the data and then use the data_pipeline function to set up 5 separate folds for validation\n",
    "CV = 5\n",
    "data2split, validation = utils.chroma_train_test_split(data, test_size=0.20)\n",
    "trains, tests = utils.data_pipeline([data2split,], x_data=x, y_data=y, cross_val = CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(CV):\n",
    "    dlr = engine.create_deterministic_linear_regressor(\n",
    "        feature_names = x,\n",
    "        target_names = y,\n",
    "        name = 'DLR_'+str(i)+'_'+filename[:-4]\n",
    "    )\n",
    "\n",
    "    pnn = engine.create_probabilistic_nn(\n",
    "        feature_names = x,\n",
    "        target_names = y,\n",
    "        hidden_units = [16,8,4,],\n",
    "        name = 'PNN_'+str(i)+'_'+filename[:-4],\n",
    "    )\n",
    "\n",
    "    models.append([dlr, pnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DLR_4_mol_res_scan_results_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            19          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "yield (Dense)                   (None, 1)            2           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "purity (Dense)                  (None, 1)            2           dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dlr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV round 0\n",
      "Start training the model DLR_0_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.738\n",
      "Test MSE: 0.739\n",
      "Start training the model PNN_0_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.082\n",
      "Test MSE: 0.086\n",
      "CV round 1\n",
      "Start training the model DLR_1_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.747\n",
      "Test MSE: 0.755\n",
      "Start training the model PNN_1_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.023\n",
      "Test MSE: 0.023\n",
      "CV round 2\n",
      "Start training the model DLR_2_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.734\n",
      "Test MSE: 0.729\n",
      "Start training the model PNN_2_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.041\n",
      "Test MSE: 0.04\n",
      "CV round 3\n",
      "Start training the model DLR_3_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.721\n",
      "Test MSE: 0.71\n",
      "Start training the model PNN_3_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.024\n",
      "Test MSE: 0.025\n",
      "CV round 4\n",
      "Start training the model DLR_4_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.721\n",
      "Test MSE: 0.727\n",
      "Start training the model PNN_4_mol_res_scan_results_7 ...\n",
      "Evaluating model performance...\n",
      "Train MSE: 0.014\n",
      "Test MSE: 0.013\n"
     ]
    }
   ],
   "source": [
    "# train all the models under the same conditions\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "optimizer = 'Adam'\n",
    "losses = ['mean_squared_error', engine.negative_loglikelihood]*2\n",
    "loss_weights = (1/trains[0][0][1].mean().div(trains[0][0][1].mean().max())).round(2).to_dict()\n",
    "histories = {}\n",
    "\n",
    "# here you're determining the MSE for each separate cross-validation\n",
    "\n",
    "for i in range(CV):\n",
    "    print('CV round '+str(i))\n",
    "    for m,l in zip(models[i], losses):\n",
    "        histories[utils.get_model_name(m,filename)] = engine.run_experiment(\n",
    "            model = m, \n",
    "            loss = {y[0]:l,y[1]:l},\n",
    "            loss_weights = loss_weights,\n",
    "            optimizer = tf.keras.optimizers.Adam,\n",
    "            learning_rate = learning_rate,\n",
    "            num_epochs = epochs,\n",
    "            train_dataset = trains[0][i], \n",
    "            test_dataset = tests[0][i],\n",
    "            verbose = 0,\n",
    "            log = 0\n",
    "            )\n",
    "\n",
    "settings = {'learning_rate' : learning_rate,\n",
    "            'epochs' : epochs,\n",
    "            'optimizer': optimizer,\n",
    "            'loss_weights': loss_weights,\n",
    "            'dataset' : filename}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('JUST': conda)",
   "name": "python375jvsc74a57bd0b01975ddddaf4db0ddd9e77ba558bc384051aec2d64c8688cf2fb07acba12100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}